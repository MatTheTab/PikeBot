{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import copy\n",
    "from utils.generator_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, loss_func, num_hanging_values, device, verbose, log, log_file, epoch, name = \"Val\"):\n",
    "    '''\n",
    "    Evaluates the model on the provided data loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader (DataLoader): DataLoader for the dataset.\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        loss_func (callable): Loss function used for evaluation.\n",
    "        num_hanging_values (int): Number of hanging values.\n",
    "        device (str): Device to run the evaluation (e.g., \"cpu\" or \"cuda\").\n",
    "        verbose (bool): Verbosity level.\n",
    "        log (bool): Flag indicating whether to log evaluation progress.\n",
    "        log_file (str): Path to the log file.\n",
    "        epoch (int): Current epoch number.\n",
    "        name (str, optional): Name of the evaluation phase (default is \"Val\").\n",
    "\n",
    "    Returns:\n",
    "        float: Total loss for the evaluation phase.\n",
    "    '''\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_MSE = 0.0\n",
    "    total_MAE = 0.0\n",
    "    total_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for X_train, y_train in loader:\n",
    "            if X_train is None and y_train is None:\n",
    "                break\n",
    "            total_examples += len(y_train)\n",
    "            hanging_vals = X_train[:, :num_hanging_values]\n",
    "            bitboards = X_train[:, num_hanging_values]\n",
    "            bitboards = np.stack(bitboards)\n",
    "            hanging_vals = torch.Tensor(hanging_vals).to(device)\n",
    "            bitboards = torch.Tensor(bitboards).to(device)\n",
    "            y_train = torch.Tensor(y_train).to(device)\n",
    "            y_preds = model(bitboards, hanging_vals)\n",
    "            loss = loss_func(y_preds, y_train)\n",
    "            total_loss += loss.item()\n",
    "            numpy_y_preds = y_preds.detach().cpu().numpy()\n",
    "            numpy_y_train = y_train.detach().cpu().numpy()\n",
    "            total_MSE += np.sum(np.square(numpy_y_train - numpy_y_preds))\n",
    "            total_MAE += np.sum(np.abs(numpy_y_train - numpy_y_preds))\n",
    "            break #TODO: delete later -> just for testing\n",
    "    if verbose:\n",
    "        print(f\"Epoch {epoch} {name} Loss: {round(total_loss/total_examples, 4)} | MSE: {round(total_MSE/total_examples, 4)} | MAE: {round(total_MAE/total_examples, 4)}\")\n",
    "    if log:\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(f\"Epoch {epoch} {name} Loss: {round(total_loss/total_examples, 4)} | MSE: {round(total_MSE/total_examples, 4)} | MAE: {round(total_MAE/total_examples, 4)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader, model, optimizer, loss_func, num_hanging_values, device, verbose, log, log_file, epoch):\n",
    "    '''\n",
    "    Performs one epoch of training.\n",
    "\n",
    "    Parameters:\n",
    "        loader (DataLoader/Generator): DataLoader for the dataset.\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer used for training.\n",
    "        loss_func (callable): Loss function used for training.\n",
    "        num_hanging_values (int): Number of hanging values.\n",
    "        device (str): Device to run the training (e.g., \"cpu\" or \"cuda\").\n",
    "        verbose (bool): Verbosity level.\n",
    "        log (bool): Flag indicating whether to log training progress.\n",
    "        log_file (str): Path to the log file.\n",
    "        epoch (int): Current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        float: Total loss for the epoch.\n",
    "    '''\n",
    "    model.train(True)\n",
    "    total_loss = 0.0\n",
    "    total_MSE = 0.0\n",
    "    total_MAE = 0.0\n",
    "    total_examples = 0\n",
    "    for X_train, y_train in loader:\n",
    "        if X_train is None and y_train is None:\n",
    "            break\n",
    "        total_examples += len(y_train)\n",
    "        optimizer.zero_grad()\n",
    "        hanging_vals = X_train[:, :num_hanging_values]\n",
    "        bitboards = X_train[:, num_hanging_values]\n",
    "        bitboards = np.stack(bitboards)\n",
    "        hanging_vals = torch.Tensor(hanging_vals).to(device)\n",
    "        bitboards = torch.Tensor(bitboards).to(device)\n",
    "        y_train = torch.Tensor(y_train).to(device)\n",
    "        y_preds = model(bitboards, hanging_vals)\n",
    "        loss = loss_func(y_preds, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        numpy_y_preds = y_preds.detach().cpu().numpy()\n",
    "        numpy_y_train = y_train.detach().cpu().numpy()\n",
    "        total_MSE += np.sum(np.square(numpy_y_train - numpy_y_preds))\n",
    "        total_MAE += np.sum(np.abs(numpy_y_train - numpy_y_preds))\n",
    "        break #TODO: delete later -> just for testing\n",
    "    if verbose:\n",
    "        print(\"______________________________________________________________\")\n",
    "        print(f\"Epoch {epoch} Train Loss: {round(total_loss/total_examples, 4)} | MSE: {round(total_MSE/total_examples, 4)} | MAE: {round(total_MAE/total_examples, 4)}\")\n",
    "    if log:\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(f\"Epoch {epoch} Train Loss: {round(total_loss/total_examples, 4)} | MSE: {round(total_MSE/total_examples, 4)} | MAE: {round(total_MAE/total_examples, 4)}\\n\")\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, test_loader, model, optimizer, loss_func, num_hanging_values, epochs, device, log = 1, log_file = \"./Training_Logs\\\\Training.txt\", verbose = 1, val = False, early_callback = False, early_callback_epochs = 100,\n",
    "          checkpoint = True, epochs_per_checkpoint = 4, break_after_checkpoint = True, checkpoint_filename = \"./Models\\\\PikeBot_Models\\\\PikeBot.pth\"):\n",
    "    '''\n",
    "    Trains a neural network model with optional checkpointing and early callback.\n",
    "\n",
    "    Parameters:\n",
    "        train_loader (DataLoader/Generator): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader/Generator): DataLoader for the validation dataset.\n",
    "        test_loader (DataLoader/Generator): DataLoader for the test dataset.\n",
    "        model (torch.nn.Module): The neural network model to be trained.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer used for training.\n",
    "        loss_func (callable): Loss function used for training.\n",
    "        num_hanging_values (int): Number of hanging values.\n",
    "        epochs (int): Number of epochs for training.\n",
    "        device (str): Device to run the training (e.g., \"cpu\" or \"cuda\").\n",
    "        log (bool): Flag indicating whether to log training progress (default is 1).\n",
    "        log_file (str, optional): Path to the log file (default is \"./Training_Logs\\\\Training.txt\").\n",
    "        verbose (bool, optional): Optional printing of the training process.\n",
    "        val (bool, optional): Flag indicating whether to validate during training (default is False).\n",
    "        early_callback (bool, optional): Flag indicating whether to use early stopping callback (default is False).\n",
    "        early_callback_epochs (int, optional): Number of epochs for early stopping (default is 100).\n",
    "        checkpoint (bool, optional): Flag indicating whether to save checkpoints during training (default is True).\n",
    "        epochs_per_checkpoint (int, optional): Number of epochs per checkpoint (default is 4).\n",
    "        break_after_checkpoint (bool, optional): Flag indicating whether to break after saving a checkpoint (default is True).\n",
    "        checkpoint_filename (str, optional): Path to save the model checkpoints (default is \"./Models\\\\PikeBot_Models\\\\PikeBot.pth\").\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Trained model.\n",
    "    '''\n",
    "    if early_callback:\n",
    "        best_val_loss = np.inf\n",
    "        no_improvement_counter = 0\n",
    "        best_model = None\n",
    "    if log:\n",
    "        if not os.path.exists(log_file):\n",
    "            open(log_file, 'a').close()\n",
    "    epoch = 0\n",
    "\n",
    "    if checkpoint and os.path.exists(checkpoint_filename):\n",
    "        if verbose:\n",
    "            print(\"Checkpoint found. Resuming training from checkpoint...\")\n",
    "        checkpoint = torch.load(checkpoint_filename)\n",
    "        epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if early_callback:\n",
    "            best_val_loss = checkpoint['best_val_loss']\n",
    "            best_model = checkpoint['best_model']\n",
    "\n",
    "    while epoch < epochs:\n",
    "        train_epoch(train_loader, model, optimizer, loss_func, num_hanging_values, device, verbose, log, log_file, epoch)\n",
    "        if val:\n",
    "            val_loss = evaluate(val_loader, model, loss_func, num_hanging_values, device, verbose, log, log_file, epoch, name = \"Val\")\n",
    "            if val_loss <= best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement_counter = 0\n",
    "                best_model = copy.deepcopy(model)\n",
    "            else:\n",
    "                no_improvement_counter += 1\n",
    "                if no_improvement_counter > early_callback_epochs:\n",
    "                    model = copy.deepcopy(best_model)\n",
    "                    if verbose:\n",
    "                        print(\"*****************\")\n",
    "                        print(\"Early Callback\")\n",
    "                        print(\"*****************\")\n",
    "                    break\n",
    "        epoch += 1\n",
    "        if checkpoint and epoch % epochs_per_checkpoint == 0:\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch}: Saving checkpoint...\")\n",
    "            if early_callback:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                    'best_model': best_model\n",
    "                }, checkpoint_filename)\n",
    "            else:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, checkpoint_filename)\n",
    "            if break_after_checkpoint:\n",
    "                break\n",
    "\n",
    "    test_loss = evaluate(test_loader, model, loss_func, num_hanging_values, device, verbose, log, log_file, epoch, name = \"Test\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_filename, onnx_filename, bitboard_input_shape, hanging_values_input_shape, opset_version = 11, device = \"cpu\"):\n",
    "    '''\n",
    "    This function saves a model in PyTorch and ONNX formats.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The PyTorch model to be saved.\n",
    "        model_filename (str): File path to save the PyTorch model.\n",
    "        onnx_filename (str): File path to save the ONNX model.\n",
    "        bitboard_input_shape (tuple): Shape of the bitboard input.\n",
    "        hanging_values_input_shape (tuple): Shape of the hanging values input.\n",
    "        opset_version (int, optional): ONNX opset version (default is 11).\n",
    "        device (str, optional): Device to run the model (default is \"cpu\").\n",
    "    '''\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    torch.save(model, model_filename)\n",
    "    input_bitboard = torch.tensor(np.random.rand(*bitboard_input_shape), dtype = torch.float32)\n",
    "    input_floats = torch.tensor(np.random.rand(*hanging_values_input_shape), dtype = torch.float32)\n",
    "    torch.onnx.export(model, (input_bitboard, input_floats), onnx_filename, opset_version=opset_version)\n",
    "    print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chess_Model(nn.Module):\n",
    "    def __init__(self, bit_board_shape, num_float_inputs, channel_multiple, concatenated_size):\n",
    "        super(Chess_Model, self).__init__()\n",
    "        self.num_channels = bit_board_shape[0]\n",
    "        self.multiple = channel_multiple\n",
    "        self.num_float_inputs = num_float_inputs\n",
    "        self.concat_size = concatenated_size\n",
    "        \n",
    "        #RESNET BLOCK 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.num_channels, out_channels=self.num_channels*self.multiple, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.num_channels*self.multiple, out_channels=self.num_channels*self.multiple, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=self.num_channels*self.multiple, out_channels=self.num_channels*self.multiple, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=self.num_channels*self.multiple, out_channels=self.num_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        #RESNET BLOCK 2\n",
    "        self.conv5 = nn.Conv2d(in_channels=self.num_channels, out_channels=self.num_channels*self.multiple, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=self.num_channels*self.multiple, out_channels=self.num_channels*self.multiple, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=self.num_channels*self.multiple, out_channels=self.num_channels*self.multiple, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=self.num_channels*self.multiple, out_channels=self.num_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.float_inputs_fc = nn.Linear(self.num_float_inputs, 512)\n",
    "        self.fc1 = nn.Linear(self.concat_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 64)\n",
    "        self.output_layer = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, bit_board, hanging_inputs):\n",
    "        conv_x = self.pool(self.ResNetBlock1(bit_board))\n",
    "        conv_x = self.pool(self.ResNetBlock2(conv_x))\n",
    "\n",
    "        conv_x = conv_x.view(conv_x.size(0), -1)\n",
    "        float_x = nn.functional.relu(self.float_inputs_fc(hanging_inputs))\n",
    "        x = torch.cat((float_x, conv_x), dim=1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x =  torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "    \n",
    "    def ResNetBlock1(self, x):\n",
    "        conv_x1 = self.conv1(x)\n",
    "        conv_x2 = self.conv2(conv_x1)\n",
    "        added1 = conv_x1 + conv_x2\n",
    "        conv_x3 =self.conv3(added1)\n",
    "        added2 = conv_x1 + conv_x2 + conv_x3\n",
    "        conv_x4 = self.conv4(added2)\n",
    "        return conv_x4 + x\n",
    "    \n",
    "    def ResNetBlock2(self, x):\n",
    "        conv_x1 = self.conv5(x)\n",
    "        conv_x2 = self.conv6(conv_x1)\n",
    "        added1 = conv_x1 + conv_x2\n",
    "        conv_x3 =self.conv7(added1)\n",
    "        added2 = conv_x1 + conv_x2 + conv_x3\n",
    "        conv_x4 = self.conv8(added2)\n",
    "        return conv_x4 + x\n",
    "    \n",
    "    def ResNetBlock3(self, x):\n",
    "        conv_x1 = self.conv9(x)\n",
    "        conv_x2 = self.conv10(conv_x1)\n",
    "        added1 = conv_x1 + conv_x2\n",
    "        conv_x3 =self.conv11(added1)\n",
    "        added2 = conv_x1 + conv_x2 + conv_x3\n",
    "        conv_x4 = self.conv12(added2)\n",
    "        return conv_x4 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    '''\n",
    "    Counts the number of parameters in the model.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "\n",
    "    Returns:\n",
    "        Int: Number of model parameters\n",
    "    '''\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model in millions: 4.828\n"
     ]
    }
   ],
   "source": [
    "model = Chess_Model(bit_board_shape = (76, 8, 8), num_float_inputs = 4, channel_multiple = 4, concatenated_size = 588)\n",
    "num_params = count_parameters(model)\n",
    "print(\"Number of parameters in the model in millions:\", round(num_params/(1e6), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chess_Model(\n",
      "  (conv1): Conv2d(76, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(304, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(76, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv6): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv7): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv8): Conv2d(304, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (float_inputs_fc): Linear(in_features=4, out_features=512, bias=True)\n",
      "  (fc1): Linear(in_features=584, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x588 and 584x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m input_bitboard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m*\u001b[39mboard_shape), dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m input_floats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m*\u001b[39mfloats_shape), dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bitboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_floats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m output\n",
      "File \u001b[1;32md:\\PikeBot\\Current\\PikeBot\\PikeBot_Model_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\PikeBot\\Current\\PikeBot\\PikeBot_Model_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m, in \u001b[0;36mChess_Model.forward\u001b[1;34m(self, bit_board, hanging_inputs)\u001b[0m\n\u001b[0;32m     32\u001b[0m float_x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloat_inputs_fc(hanging_inputs))\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((float_x, conv_x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x))\n",
      "File \u001b[1;32md:\\PikeBot\\Current\\PikeBot\\PikeBot_Model_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\PikeBot\\Current\\PikeBot\\PikeBot_Model_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\PikeBot\\Current\\PikeBot\\PikeBot_Model_Env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x588 and 584x1024)"
     ]
    }
   ],
   "source": [
    "board_shape = (1, 76, 8, 8)\n",
    "floats_shape = (1, 4)\n",
    "input_bitboard = torch.tensor(np.random.rand(*board_shape), dtype = torch.float32)\n",
    "input_floats = torch.tensor(np.random.rand(*floats_shape), dtype = torch.float32)\n",
    "output = model(input_bitboard, input_floats)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_func = nn.BCELoss()\n",
    "NUM_HANGING_VALUES = 4\n",
    "EPOCHS = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Detected Device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = load_object(\"./Generators\\\\train_generator.pkl\")\n",
    "train_generator.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = load_object(\"./Generators\\\\val_generator.pkl\")\n",
    "val_generator.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = load_object(\"./Generators\\\\test_generator.pkl\")\n",
    "test_generator.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(train_generator, val_generator, test_generator, model, optimizer, loss_func, NUM_HANGING_VALUES, EPOCHS, device, log = 1, log_file = \"./Training_Logs\\\\Training.txt\", verbose = 1, val = True, early_callback=False, early_callback_epochs=None,\n",
    "              checkpoint=True, epochs_per_checkpoint=4, break_after_checkpoint=False, checkpoint_filename=\"./Models\\\\PikeBot_Models\\\\PikeBot_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, model_filename = \"./Models\\\\PikeBot_Models\\\\PikeBot.pth\", onnx_filename= \"./Models\\\\PikeBot_Models\\\\PikeBot.onnx\", bitboard_input_shape = (1, 76, 8, 8), hanging_values_input_shape = (1, 4), opset_version=11, device=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PikeBot_Model_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
