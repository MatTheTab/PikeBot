{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 19:17:09.208213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from utils.model_utils import *\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Device: cuda\n"
     ]
    }
   ],
   "source": [
    "LR = 0.1\n",
    "loss_func = nn.BCELoss()\n",
    "NUM_HANGING_VALUES = 10\n",
    "EPOCHS = 30\n",
    "BITBOARD_SHAPE = (76*2, 8, 8)\n",
    "CHANGE_LEARNING_RATE = True\n",
    "UPDATE_EPOCHS = [4, 10, 15]\n",
    "RESIDUAL_BLOCKS = 6\n",
    "RESIDUAL_FILTERS = 64\n",
    "SE_RATIO = 8\n",
    "MODEL_FILENAME = \"./Models/PikeBot_Models/PikeBot.pth\"\n",
    "ONNX_FILENAME = \"./Models/PikeBot_Models/PikeBot.onnx\"\n",
    "LOG_FILE_LOCATION = \"./Training_Logs/Training.txt\"\n",
    "CHECKPOINT_FILENAME_LOCATION = \"./Models/PikeBot_Models/PikeBot_checkpoint.pth\"\n",
    "TRAIN_GENERATOR_PATH = \"./Generators/train_generator.pkl\"\n",
    "VAL_GENERATOR_PATH = \"./Generators/val_generator.pkl\"\n",
    "TEST_GENERATOR_PATH = \"./Generators/test_generator.pkl\"\n",
    "TEMP_STATE_PATH = \"./Models/PikeBot_Models/temp_state_dict.pth\"\n",
    "OPSET_VERSION = 11\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(f\"Detected Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model in millions: 3.8303\n"
     ]
    }
   ],
   "source": [
    "model = ChessModel_V2(bit_board_shape=BITBOARD_SHAPE, num_float_inputs=NUM_HANGING_VALUES, residual_blocks=RESIDUAL_BLOCKS, residual_filters=RESIDUAL_FILTERS, se_ratio=SE_RATIO)\n",
    "#model = Chess_Model(bit_board_shape=BITBOARD_SHAPE, num_float_inputs=NUM_HANGING_VALUES, channel_multiple=2)\n",
    "num_params = count_parameters(model)\n",
    "print(\"Number of parameters in the model in millions:\", round(num_params/(1e6), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChessModel_V2(\n",
      "  (relu): ReLU()\n",
      "  (conv_block): ConvBlockV2(\n",
      "    (conv): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (residual_blocks): Sequential(\n",
      "    (0): ResidualBlockV2(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SqueezeExcitationV2(\n",
      "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlockV2(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SqueezeExcitationV2(\n",
      "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlockV2(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SqueezeExcitationV2(\n",
      "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResidualBlockV2(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SqueezeExcitationV2(\n",
      "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): ResidualBlockV2(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SqueezeExcitationV2(\n",
      "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): ResidualBlockV2(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SqueezeExcitationV2(\n",
      "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv_val): ConvBlockV2(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=2058, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=32, bias=True)\n",
      "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5322]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "board_shape = (1, BITBOARD_SHAPE[0], BITBOARD_SHAPE[1], BITBOARD_SHAPE[2])\n",
    "floats_shape = (1, NUM_HANGING_VALUES)\n",
    "input_bitboard = torch.tensor(np.random.rand(*board_shape), dtype = torch.float32)\n",
    "input_floats = torch.tensor(np.random.rand(*floats_shape), dtype = torch.float32)\n",
    "output = model(input_bitboard, input_floats)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625695"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = efficent_load_object(TRAIN_GENERATOR_PATH)\n",
    "train_generator.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator = efficent_load_object(VAL_GENERATOR_PATH)\n",
    "val_generator.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = efficent_load_object(TEST_GENERATOR_PATH)\n",
    "test_generator.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_generator\n",
    "del val_generator\n",
    "del test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________\n",
      "Epoch 0 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 0 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 1: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 1 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 1 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 2: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 2 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 2 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 3: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 3 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 3 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 4: Saving checkpoint...\n",
      "Updated the learning rate, current learning rate: 0.010000000000000002\n",
      "______________________________________________________________\n",
      "Epoch 4 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 4 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 5: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 5 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 5 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 6: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 6 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 6 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 7: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 7 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 7 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 8: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 8 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 8 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 9: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 9 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 9 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 10: Saving checkpoint...\n",
      "Updated the learning rate, current learning rate: 0.0010000000000000002\n",
      "______________________________________________________________\n",
      "Epoch 10 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 10 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 11: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 11 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 11 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 12: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 12 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 12 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 13: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 13 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 13 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 14: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 14 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 14 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 15: Saving checkpoint...\n",
      "Updated the learning rate, current learning rate: 0.00010000000000000003\n",
      "______________________________________________________________\n",
      "Epoch 15 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 15 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 16: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 16 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 16 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 17: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 17 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 17 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 18: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 18 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 18 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 19: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 19 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 19 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 20: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 20 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 20 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 21: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 21 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 21 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 22: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 22 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 22 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 23: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 23 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 23 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 24: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 24 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 24 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 25: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 25 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 25 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 26: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 26 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 26 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 27: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 27 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 27 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 28: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 28 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 28 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 29: Saving checkpoint...\n",
      "______________________________________________________________\n",
      "Epoch 29 Train Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n",
      "Epoch 29 Val Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n",
      "Epoch 30: Saving checkpoint...\n",
      "Epoch 30 Test Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037  | Accuracy: 0.4963\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model = train(TRAIN_GENERATOR_PATH, VAL_GENERATOR_PATH, TEST_GENERATOR_PATH, model, optimizer, loss_func, NUM_HANGING_VALUES, EPOCHS, device,\n",
    "              learning_rate=LR, log = 1, log_file = \"./Training_Logs/Training.txt\", verbose = 1, val = True, early_callback=False, early_callback_epochs=None,\n",
    "              checkpoint=True, epochs_per_checkpoint=1, break_after_checkpoint=False, checkpoint_filename=\"./Models/PikeBot_Models/PikeBot_checkpoint.pth\",\n",
    "              change_learning_rate=CHANGE_LEARNING_RATE, update_epochs=UPDATE_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChessModel_V2(\n",
       "  (relu): ReLU()\n",
       "  (conv_block): ConvBlockV2(\n",
       "    (conv): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (residual_blocks): Sequential(\n",
       "    (0): ResidualBlockV2(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SqueezeExcitationV2(\n",
       "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlockV2(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SqueezeExcitationV2(\n",
       "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlockV2(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SqueezeExcitationV2(\n",
       "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlockV2(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SqueezeExcitationV2(\n",
       "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): ResidualBlockV2(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SqueezeExcitationV2(\n",
       "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): ResidualBlockV2(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SqueezeExcitationV2(\n",
       "        (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv_val): ConvBlockV2(\n",
       "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (fc1): Linear(in_features=2058, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  (fc3): Linear(in_features=4096, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), TEMP_STATE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8379/2006316502.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(TEMP_STATE_PATH))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model = ChessModel_V2(bit_board_shape=BITBOARD_SHAPE, num_float_inputs=NUM_HANGING_VALUES, residual_blocks=RESIDUAL_BLOCKS, residual_filters=RESIDUAL_FILTERS, se_ratio=SE_RATIO)\n",
    "model.load_state_dict(torch.load(TEMP_STATE_PATH))\n",
    "save_model(model, model_filename=MODEL_FILENAME, onnx_filename=ONNX_FILENAME,\n",
    "           bitboard_input_shape=board_shape, hanging_values_input_shape=floats_shape, opset_version=OPSET_VERSION, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8379/1681273878.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(MODEL_FILENAME)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Complete, Loss: 0.7871 | MSE: 0.5037 | MAE: 0.5037 | Accuracy: 0.4963\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(MODEL_FILENAME)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "test_model(model, loss_func=loss_func, num_hanging_values=NUM_HANGING_VALUES, device=device, test_generator_path=TEST_GENERATOR_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PikeBot_Model_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
